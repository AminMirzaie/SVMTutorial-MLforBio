{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sort_approx.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3TqXUO+8871M4d08drVsS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AminMirzaie/SVMTutorial-MLforBio/blob/master/neuralNDCG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkUzbX6hp9b1"
      },
      "source": [
        "# !pip install pandas==1.2.2\n",
        "# !pip install sklearn numerapi\n",
        "# !pip install pytorch-metric-learning\n",
        "# !pip install pkbar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYw_R_DijX6y"
      },
      "source": [
        "import numpy as np\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import numerapi\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import NMF\n",
        "import pkbar\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import scipy.stats\n",
        "from datetime import datetime\n",
        "\n",
        "from pytorch_metric_learning import losses\n",
        "\n",
        "\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRt-lMXiqNJi"
      },
      "source": [
        "napi = numerapi.NumerAPI(public_id=\"U6GQVKDZCAX3PZCUVZU5YG4KKUZXEHKY\",\n",
        "                         secret_key=\"SHIGGP34Q7ODY5LIA55S7CT3FH4BZUPVXOIEPUVWTDY6F3S6OXH2WA7KJQ7QSHWG\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "3PMFqbQxqP-N",
        "outputId": "d703af5f-a19b-4fdf-9c18-0a40c7bc31b2"
      },
      "source": [
        "napi.download_current_dataset(unzip=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-20 09:20:28,252 INFO numerapi.utils: starting download\n",
            "./numerai_dataset_264.zip: 404MB [00:07, 53.8MB/s]                           \n",
            "2021-05-20 09:20:35,776 INFO numerapi.base_api: unzipping file...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./numerai_dataset_264.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZOjttZFqn6b"
      },
      "source": [
        "class FastTensorDataLoader:\n",
        "    \"\"\"\n",
        "    A DataLoader-like object for a set of tensors that can be much faster than\n",
        "    TensorDataset + DataLoader because dataloader grabs individual indices of\n",
        "    the dataset and calls cat (slow).\n",
        "    Source: https://discuss.pytorch.org/t/dataloader-much-slower-than-manual-batching/27014/6\n",
        "    \"\"\"\n",
        "    def __init__(self, *tensors, batch_size=32, shuffle=False):\n",
        "        \"\"\"\n",
        "        Initialize a FastTensorDataLoader.\n",
        "        :param *tensors: tensors to store. Must have the same length @ dim 0.\n",
        "        :param batch_size: batch size to load.\n",
        "        :param shuffle: if True, shuffle the data *in-place* whenever an\n",
        "            iterator is created out of this object.\n",
        "        :returns: A FastTensorDataLoader.\n",
        "        \"\"\"\n",
        "        assert all(t.shape[0] == tensors[0].shape[0] for t in tensors)\n",
        "        self.tensors = tensors\n",
        "\n",
        "        self.dataset_len = self.tensors[0].shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # Calculate # batches\n",
        "        n_batches, remainder = divmod(self.dataset_len, self.batch_size)\n",
        "        if remainder > 0:\n",
        "            n_batches += 1\n",
        "        self.n_batches = n_batches\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            r = torch.randperm(self.dataset_len)\n",
        "            self.tensors = [t[r] for t in self.tensors]\n",
        "        self.i = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.i >= self.dataset_len:\n",
        "            raise StopIteration\n",
        "        batch = tuple(t[self.i:self.i+self.batch_size] for t in self.tensors)\n",
        "        self.i += self.batch_size\n",
        "        return batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9LsZRs2rIT8"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(310, 256, bias=True)\n",
        "        self.b1 = nn.BatchNorm1d(256)\n",
        "        self.l2 = nn.Linear(256, 128, bias=True)\n",
        "        self.b2 = nn.BatchNorm1d(128)\n",
        "        self.l3 = nn.Linear(128, 64, bias=True)\n",
        "        self.b3 = nn.BatchNorm1d(64)\n",
        "        self.l4 = nn.Linear(64, 32, bias=True)\n",
        "        self.b4 = nn.BatchNorm1d(32)\n",
        "        self.l5 = nn.Linear(32, 16, bias=True)\n",
        "        self.b5 = nn.BatchNorm1d(16)\n",
        "        self.l6 = nn.Linear(16, 8, bias=True)\n",
        "        self.b6 = nn.BatchNorm1d(8)\n",
        "        self.l7 = nn.Linear(8, 1, bias=True)\n",
        "        self.b7 = nn.BatchNorm1d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(F.relu(self.l1(x)))\n",
        "        x = self.b2(F.relu(self.l2(x)))\n",
        "        x = self.b3(F.relu(self.l3(x)))\n",
        "        x = self.b4(F.relu(self.l4(x)))\n",
        "        x = self.b5(F.relu(self.l5(x)))\n",
        "        last = self.b6(F.relu(self.l6(x)))\n",
        "        x = self.b7(F.relu(self.l7(last)))\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmTXnSZLTRrQ"
      },
      "source": [
        "train_data = pd.read_csv(\"numerai_dataset_264/numerai_training_data.csv\").set_index(\"id\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Kf809irtkD"
      },
      "source": [
        "feature_cols = train_data.columns[train_data.columns.str.startswith('feature')]\n",
        "feature_map_dic = {}\n",
        "colnames = train_data[feature_cols].columns\n",
        "for i in range(310):\n",
        "  feature_map_dic[i] = colnames[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bFqixlgKV3m"
      },
      "source": [
        "train_data[\"erano\"] = train_data.era.str.slice(3).astype(int)\n",
        "feature_cols = train_data.columns[train_data.columns.str.startswith('feature')]\n",
        "train_data = train_data.astype({k: 'float32' for k in (feature_cols.to_list()+['target'])})\n",
        "feature_groups = {\n",
        "    g: [c for c in train_data if c.startswith(f\"feature_{g}\")]\n",
        "    for g in [\"intelligence\", \"wisdom\", \"charisma\", \"dexterity\", \"strength\", \"constitution\"]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW71aTN5IXeQ"
      },
      "source": [
        "batch_size = 100\n",
        "\n",
        "train_loader_dict = {}\n",
        "train_loader_era_wise = {}\n",
        "train_numpy_feat = []\n",
        "train_numpy_label = []\n",
        "for erano in train_data[\"erano\"].unique():\n",
        "  data = train_data[train_data[\"erano\"] == erano]\n",
        "  train_data_era, val_data_era = train_test_split(data, test_size=0.07, shuffle=True)\n",
        "  train_loader_era_wise[erano] = {\"train\": FastTensorDataLoader(torch.from_numpy(train_data_era[feature_cols].values), \n",
        "                                                    torch.from_numpy(train_data_era[\"target\"].values), \n",
        "                                                    batch_size=batch_size, shuffle=True),\n",
        "                                  \"val\": FastTensorDataLoader(torch.from_numpy(val_data_era[feature_cols].values), \n",
        "                                                    torch.from_numpy(val_data_era[\"target\"].values), \n",
        "                                                    batch_size=val_data_era.shape[0], shuffle=True)}\n",
        "    \n",
        "\n",
        "  "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdagdfePTgLU"
      },
      "source": [
        "# for k in range(2):\n",
        "#   for i,data in enumerate(train_loader_era_wise[1][\"train\"],0):\n",
        "#     labels = data[1]\n",
        "#     data = data[0]\n",
        "#     print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2OrUvxiokk9"
      },
      "source": [
        "def softmax(a):\n",
        "  return torch.exp(a) / torch.sum(torch.exp(a))\n",
        "\n",
        "def gain(scores):\n",
        "  return torch.pow(2,scores) - 1\n",
        "\n",
        "def discount(scores):\n",
        "  n = scores.shape[0]\n",
        "  discount = torch.log2(torch.arange(1,n+1)+1)\n",
        "  discount = discount.cuda()\n",
        "  return discount\n",
        "def permutation_estimator(scores,thau):\n",
        "  n = scores.shape[0]\n",
        "  scores = scores.reshape((n,1))\n",
        "  As = torch.empty((n,n))\n",
        "  As = As.cuda()\n",
        "  for i in range(As.shape[0]):\n",
        "    for j in range(As.shape[1]):\n",
        "      As[i,j] = abs(scores[i] - scores[j])\n",
        "  ones = torch.ones((n,1))\n",
        "  ones = ones.cuda()\n",
        "  permute = torch.zeros((n,n))\n",
        "  permute = permute.cuda()\n",
        "  for i in range(1,n+1):\n",
        "    permute[i-1,:] = softmax(((n+1-(2*i))*scores - torch.matmul(As,ones) )/ thau).reshape(n)\n",
        "  \n",
        "  return permute"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xd5MnsaUtW3F"
      },
      "source": [
        "def NCDG_loss(outputs,labels,norm):\n",
        "  p_hat = permutation_estimator(outputs,10)\n",
        "  d = discount(labels)\n",
        "  g = gain(labels)\n",
        "  m = torch.mul(g,torch.matmul(p_hat,d))/norm\n",
        "  loss = torch.sum(m)\n",
        "  return loss"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mTCQCRiH3qR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37e075da-c1a1-42a5-ad47-c8aedf4f2d86"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "startTime = datetime.now()\n",
        "\n",
        "net = Net()\n",
        "net = net.cuda()\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
        "# scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pbar = pkbar.Pbar(name='training', target=int(train_loader_era_wise[1][\"train\"].dataset_len /batch_size) )\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(60):  # loop over the dataset multiple times\n",
        "  counter = 0\n",
        "  for i, data in enumerate(train_loader_era_wise[1][\"train\"], 0):\n",
        "    pbar.update(counter)\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    sort_labels,_ = torch.sort(labels,descending=True)\n",
        "    norm_factor = torch.sum((torch.mul(gain(sort_labels),discount(sort_labels))))\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    print(labels,outputs.reshape(outputs.shape[0]))\n",
        "    loss = NCDG_loss(outputs, labels,norm_factor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    counter+=1\n",
        "  print(\"\\n average loss = \", running_loss/train_loader_era_wise[1][\"train\"].dataset_len /batch_size)\n",
        "  running_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(train_loader_era_wise[1][\"val\"], 0):\n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs= net(inputs)\n",
        "      cor = scipy.stats.spearmanr(outputs.detach().cpu().numpy(), labels.detach().cpu().numpy())[0]\n",
        "      print('Validation cor  : %f %%' % (cor))\n",
        "\n",
        "    # if counter % 100 == 99:\n",
        "      # scheduler.step()\n",
        "      # print(\"new LR = \", scheduler.get_last_lr())\n",
        "  # with torch.no_grad():\n",
        "  #   running_loss = 0.0\n",
        "  #   correct = 0\n",
        "  #   total = 0\n",
        "  #   for data in val_loader:\n",
        "  #     inputs, labels = data\n",
        "  #     inputs = inputs.to(device)\n",
        "  #     labels = labels.to(device)\n",
        "  #     outputs,_ = net(inputs)\n",
        "  #     _, predicted = torch.max(outputs.data, 1)\n",
        "  #     total += labels.size(0)\n",
        "  #     correct += (predicted == labels).sum().item()\n",
        "\n",
        "  #   print('Validation Accuracy: %d %%' % (100 * correct / total))\n",
        "              \n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for data in train_loader:\n",
        "#       inputs, labels = data\n",
        "#       inputs = inputs.to(device)\n",
        "#       labels = labels.to(device)\n",
        "#       outputs,_ = net(inputs)\n",
        "#       _, predicted = torch.max(outputs.data, 1)\n",
        "#       total += labels.size(0)\n",
        "#       correct += (predicted == labels).sum().item()\n",
        "#     print('train Accuracy: %d %%' % (100 * correct / total))\n",
        "#   torch.save(net.state_dict(), \"./drive/MyDrive/inv2/kotche_for_feature_\"+str(feature_number))  "
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training\n",
            "\r 1/22  [>.............................] - 0.0stensor([0.2500, 0.5000, 0.7500, 0.5000, 0.5000, 0.2500, 0.2500, 0.5000, 0.2500,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.5000, 0.5000, 0.7500, 0.5000,\n",
            "        0.5000, 0.2500, 0.7500, 0.2500, 0.5000, 0.7500, 0.5000, 0.5000, 0.7500,\n",
            "        0.7500, 0.0000, 0.5000, 0.5000, 0.2500, 0.0000, 0.5000, 0.2500, 0.5000,\n",
            "        0.5000, 0.0000, 0.5000, 0.7500, 0.5000, 0.2500, 0.5000, 0.2500, 0.7500,\n",
            "        0.5000, 0.5000, 0.2500, 0.0000, 0.5000, 0.5000, 0.5000, 0.7500, 0.5000,\n",
            "        0.7500, 0.2500, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.7500, 0.7500,\n",
            "        0.5000, 1.0000, 1.0000, 0.5000, 0.5000, 0.7500, 0.2500, 0.5000, 0.0000,\n",
            "        0.5000, 0.7500, 0.5000, 1.0000, 0.2500, 0.7500, 0.2500, 0.5000, 0.5000,\n",
            "        0.7500, 1.0000, 1.0000, 0.5000, 0.7500, 0.7500, 0.5000, 0.5000, 0.2500,\n",
            "        0.5000, 0.2500, 0.5000, 0.5000, 1.0000, 0.5000, 1.0000, 0.2500, 0.5000,\n",
            "        0.7500], device='cuda:0') tensor([-0.4753,  0.6909,  0.7744,  0.9804, -0.4753,  0.7010,  0.8191, -0.4753,\n",
            "        -0.4753, -0.4753, -0.4430, -0.4753, -0.4753, -0.4753, -0.4753, -0.4753,\n",
            "         1.6511, -0.4753, -0.0518, -0.4753, -0.0069, -0.0551,  0.5522, -0.4753,\n",
            "        -0.1098, -0.4753, -0.4753, -0.4753, -0.2368,  3.8916,  1.4036, -0.4753,\n",
            "        -0.4753, -0.4753, -0.4753, -0.4753,  4.4798,  0.7348, -0.4753, -0.4753,\n",
            "        -0.4753, -0.4753, -0.4753, -0.4753, -0.4753,  0.4521, -0.4753, -0.4753,\n",
            "        -0.4753, -0.4753,  4.3854, -0.4753, -0.4753,  0.8102, -0.4753,  0.3984,\n",
            "        -0.4753, -0.4753,  2.1822, -0.4753, -0.4753, -0.4753, -0.4753,  2.5441,\n",
            "        -0.4753, -0.4753, -0.4753, -0.4753, -0.4753, -0.4753,  0.1543,  0.5401,\n",
            "        -0.4753, -0.4753, -0.4753, -0.4753, -0.4753, -0.4753, -0.4753,  0.9563,\n",
            "        -0.4753, -0.4753, -0.4753, -0.4753, -0.4753,  0.9614, -0.1070, -0.3747,\n",
            "        -0.4753, -0.4753, -0.4753,  2.5814, -0.4753,  0.3097, -0.4753,  0.0420,\n",
            "        -0.4753,  0.2341, -0.4753, -0.4753], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 2/22  [=>............................] - 2.1stensor([0.5000, 0.0000, 0.7500, 0.2500, 0.5000, 0.5000, 0.2500, 0.7500, 0.5000,\n",
            "        0.7500, 0.7500, 0.2500, 0.5000, 0.5000, 0.7500, 0.5000, 0.2500, 1.0000,\n",
            "        0.7500, 0.2500, 0.2500, 0.0000, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.2500, 0.5000, 0.5000, 0.7500, 1.0000, 0.5000, 1.0000, 0.2500, 0.2500,\n",
            "        0.5000, 1.0000, 0.2500, 0.7500, 0.2500, 0.5000, 0.7500, 0.2500, 0.5000,\n",
            "        0.5000, 0.2500, 0.0000, 0.7500, 0.7500, 0.5000, 0.2500, 0.5000, 0.2500,\n",
            "        0.2500, 0.0000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.7500, 0.5000,\n",
            "        1.0000, 0.5000, 0.7500, 0.5000, 0.5000, 0.5000, 0.2500, 0.7500, 0.5000,\n",
            "        0.5000, 0.0000, 0.0000, 1.0000, 0.2500, 0.7500, 0.2500, 0.2500, 0.2500,\n",
            "        0.2500, 0.2500, 0.7500, 0.2500, 0.2500, 0.0000, 0.7500, 0.7500, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.7500, 0.5000, 1.0000, 0.5000,\n",
            "        0.5000], device='cuda:0') tensor([-0.3808, -0.3808,  0.1328, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808,\n",
            "        -0.3808, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808,  0.0155, -0.3808,\n",
            "        -0.3808,  0.6923, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808,\n",
            "        -0.3808,  3.1635,  0.5452, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808,\n",
            "        -0.3808, -0.3808,  0.4925, -0.3808, -0.3808, -0.3808, -0.3808, -0.2143,\n",
            "        -0.3808, -0.3808, -0.3808, -0.3808,  2.2091, -0.3808, -0.3808, -0.3808,\n",
            "        -0.3808, -0.3808, -0.3808, -0.3808,  0.0188, -0.3808, -0.3808,  2.8313,\n",
            "        -0.3808,  4.9869, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808,\n",
            "        -0.3808,  1.5948,  1.8242,  4.3399, -0.1342, -0.3808, -0.3808, -0.3808,\n",
            "        -0.3808, -0.3808,  0.9430, -0.3808,  0.2789, -0.3808,  0.1816, -0.3808,\n",
            "         1.2735, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808,\n",
            "        -0.3808,  2.1062, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808, -0.3808,\n",
            "         2.8043, -0.3808, -0.3808, -0.3808], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 3/22  [===>..........................] - 4.2stensor([0.7500, 0.2500, 0.2500, 0.7500, 0.5000, 0.7500, 0.2500, 0.2500, 0.7500,\n",
            "        0.2500, 1.0000, 0.5000, 0.2500, 0.5000, 0.0000, 0.2500, 0.5000, 0.7500,\n",
            "        0.5000, 0.7500, 0.2500, 0.7500, 0.5000, 0.2500, 0.7500, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.0000, 0.2500, 0.5000, 0.0000, 0.5000, 1.0000, 0.2500,\n",
            "        0.5000, 0.7500, 0.5000, 0.5000, 0.0000, 1.0000, 0.2500, 1.0000, 0.5000,\n",
            "        0.7500, 0.2500, 1.0000, 0.5000, 0.5000, 0.2500, 0.5000, 0.0000, 0.5000,\n",
            "        0.5000, 0.2500, 0.7500, 0.2500, 0.7500, 0.5000, 0.2500, 0.5000, 0.2500,\n",
            "        0.7500, 0.5000, 0.2500, 0.5000, 0.7500, 0.2500, 0.7500, 0.7500, 0.5000,\n",
            "        1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.0000,\n",
            "        0.7500, 0.2500, 0.5000, 0.5000, 0.7500, 0.5000, 0.7500, 0.2500, 0.5000,\n",
            "        0.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7500, 0.2500, 0.5000, 0.0000,\n",
            "        0.2500], device='cuda:0') tensor([-0.4544, -0.4544,  2.8977, -0.4544, -0.4544,  0.3430, -0.4544, -0.4544,\n",
            "        -0.0429,  0.5628,  2.2373, -0.4544, -0.4544, -0.3117, -0.4544, -0.4544,\n",
            "        -0.4544,  1.6651, -0.4544, -0.3476, -0.4544,  0.5666, -0.4544, -0.4544,\n",
            "        -0.4544, -0.4544, -0.4544, -0.4544, -0.4544,  1.1488,  0.7260,  1.6738,\n",
            "        -0.4544, -0.4544, -0.4544,  1.1224, -0.4544,  4.9730, -0.4544, -0.4544,\n",
            "        -0.4544, -0.4544,  0.1915, -0.4544, -0.4544, -0.4544, -0.4544, -0.4544,\n",
            "         1.5051, -0.4544, -0.4544, -0.0732, -0.4544, -0.4544, -0.4544, -0.4544,\n",
            "        -0.4544, -0.4544,  1.4394,  0.1846, -0.4544, -0.4544, -0.4544, -0.4544,\n",
            "         1.1845,  0.0767, -0.4418, -0.4544, -0.4544, -0.4544, -0.4544,  3.5403,\n",
            "        -0.4544, -0.4544,  2.9624, -0.4544, -0.4544, -0.4544, -0.4544, -0.4544,\n",
            "         1.6508, -0.4544, -0.4544, -0.4544, -0.4544, -0.4544,  2.0019, -0.4544,\n",
            "        -0.4544,  1.7323, -0.4544, -0.4544, -0.4544, -0.4544, -0.4544, -0.4544,\n",
            "        -0.4544, -0.4544, -0.4544, -0.4544], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 4/22  [====>.........................] - 6.2stensor([0.7500, 0.5000, 0.2500, 0.5000, 0.5000, 0.0000, 0.2500, 0.5000, 0.5000,\n",
            "        0.2500, 0.5000, 0.2500, 0.7500, 0.7500, 0.5000, 0.7500, 0.7500, 0.5000,\n",
            "        0.2500, 0.0000, 0.5000, 1.0000, 0.2500, 0.5000, 0.7500, 0.2500, 0.2500,\n",
            "        0.5000, 0.7500, 0.5000, 0.2500, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000,\n",
            "        0.2500, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000, 0.5000, 0.7500,\n",
            "        0.7500, 0.7500, 0.5000, 0.7500, 0.7500, 0.2500, 0.5000, 0.5000, 0.2500,\n",
            "        0.0000, 0.0000, 0.7500, 0.0000, 0.7500, 0.2500, 0.7500, 0.7500, 0.5000,\n",
            "        0.5000, 0.5000, 0.7500, 0.7500, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000,\n",
            "        0.5000, 0.2500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000,\n",
            "        0.5000, 0.2500, 0.5000, 0.2500, 0.7500, 0.5000, 0.5000, 0.5000, 0.7500,\n",
            "        0.2500, 0.5000, 0.5000, 0.7500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000], device='cuda:0') tensor([-0.4970, -0.4970, -0.4970, -0.4970, -0.4970, -0.4970,  2.2112, -0.2445,\n",
            "        -0.4970, -0.4970, -0.4970,  0.7420, -0.4970, -0.4970, -0.4970,  0.8193,\n",
            "        -0.4970, -0.4970,  2.3290, -0.4970, -0.4970, -0.4970,  1.3821, -0.4970,\n",
            "        -0.4970, -0.4970, -0.4970, -0.4970, -0.4970, -0.4970, -0.4970, -0.4970,\n",
            "         0.9463, -0.4970,  1.1502, -0.2340, -0.4970, -0.4970, -0.4970, -0.3525,\n",
            "        -0.4970, -0.4970, -0.4970, -0.4970,  1.1686, -0.4970, -0.4970, -0.4970,\n",
            "        -0.4970, -0.4970, -0.4970,  2.8415,  0.1436,  0.5374,  2.6370,  2.0995,\n",
            "        -0.4970, -0.4970, -0.4970, -0.0556, -0.4970, -0.4970, -0.4970,  4.2095,\n",
            "        -0.4970, -0.4970, -0.4970, -0.4970, -0.4970, -0.4970, -0.4970,  1.4016,\n",
            "        -0.4970,  0.3043, -0.4970,  0.7234, -0.4970,  0.4516, -0.4970, -0.4970,\n",
            "         0.9672,  1.1700,  1.3179, -0.4970, -0.4970,  3.1679, -0.4970,  3.1449,\n",
            "        -0.4970, -0.4970, -0.4970, -0.4970,  0.8027, -0.4970, -0.4970, -0.4970,\n",
            "        -0.4970, -0.4970, -0.4970, -0.4970], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 5/22  [=====>........................] - 8.2stensor([0.7500, 0.5000, 0.7500, 0.7500, 0.2500, 0.7500, 1.0000, 0.7500, 0.5000,\n",
            "        0.5000, 0.7500, 0.5000, 0.0000, 0.2500, 0.7500, 0.5000, 0.5000, 0.5000,\n",
            "        0.7500, 0.5000, 0.0000, 0.7500, 0.5000, 0.2500, 0.2500, 0.2500, 0.7500,\n",
            "        0.2500, 0.5000, 0.7500, 1.0000, 1.0000, 0.5000, 0.2500, 0.5000, 0.2500,\n",
            "        0.5000, 0.2500, 0.2500, 0.2500, 0.7500, 0.7500, 0.5000, 0.2500, 0.0000,\n",
            "        0.5000, 0.7500, 0.2500, 0.2500, 0.2500, 0.5000, 0.2500, 0.2500, 0.2500,\n",
            "        0.2500, 1.0000, 0.7500, 0.5000, 0.5000, 0.2500, 0.7500, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.7500, 0.2500, 0.7500, 0.5000, 0.2500,\n",
            "        0.5000, 0.5000, 0.7500, 0.2500, 0.5000, 0.2500, 0.2500, 0.2500, 0.5000,\n",
            "        1.0000, 0.0000, 0.5000, 0.0000, 0.5000, 0.7500, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 1.0000, 0.7500, 0.5000, 0.7500, 0.2500, 0.2500,\n",
            "        0.5000], device='cuda:0') tensor([-0.3731,  0.7450, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731,\n",
            "        -0.3731, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731,\n",
            "        -0.3731, -0.3731,  0.0331,  0.3432,  0.9743,  4.3761,  2.0096, -0.3731,\n",
            "        -0.3731, -0.3731, -0.3731, -0.3731, -0.1991, -0.3731, -0.3731, -0.0202,\n",
            "        -0.2194, -0.3731, -0.3731, -0.1247, -0.2981,  0.7940, -0.3731, -0.3731,\n",
            "        -0.3731, -0.3699, -0.3731, -0.3731, -0.3731, -0.3247, -0.3731, -0.3731,\n",
            "        -0.3731, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731,\n",
            "         0.2128, -0.3731, -0.3731, -0.3731,  0.8465,  2.7747, -0.3731, -0.3731,\n",
            "         1.3862, -0.3731, -0.3731,  1.9811, -0.3731, -0.3731, -0.2103, -0.3731,\n",
            "        -0.3731, -0.3731, -0.3731,  1.2545, -0.3731, -0.3731, -0.3731, -0.3731,\n",
            "         1.9569, -0.3731,  6.0566, -0.3731, -0.3731,  2.6018, -0.3731, -0.3731,\n",
            "        -0.1215,  0.8371, -0.0610, -0.3731, -0.3731, -0.3731, -0.3731, -0.3731,\n",
            "        -0.3731, -0.3731, -0.3731, -0.3731], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 6/22  [=======>......................] - 10.3stensor([1.0000, 0.7500, 1.0000, 0.7500, 0.5000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
            "        0.5000, 0.2500, 0.5000, 0.7500, 0.7500, 0.5000, 0.2500, 0.2500, 0.2500,\n",
            "        0.5000, 0.5000, 0.5000, 1.0000, 0.5000, 0.5000, 0.5000, 1.0000, 0.7500,\n",
            "        0.2500, 0.7500, 0.7500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7500,\n",
            "        0.5000, 0.2500, 0.5000, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.7500, 0.5000, 0.2500, 0.5000, 0.2500, 0.5000,\n",
            "        0.2500, 0.7500, 0.2500, 0.2500, 0.2500, 0.5000, 0.7500, 0.5000, 0.7500,\n",
            "        0.5000, 0.5000, 0.2500, 0.2500, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000,\n",
            "        0.7500, 0.7500, 0.2500, 0.5000, 0.2500, 0.5000, 0.5000, 0.5000, 0.2500,\n",
            "        0.2500, 0.5000, 0.5000, 0.5000, 1.0000, 0.2500, 0.7500, 0.5000, 0.7500,\n",
            "        0.7500, 1.0000, 0.7500, 0.2500, 0.7500, 0.5000, 0.7500, 0.5000, 0.5000,\n",
            "        0.5000], device='cuda:0') tensor([ 1.0824, -0.4236, -0.4236, -0.4236, -0.4236, -0.4236, -0.4236, -0.4236,\n",
            "        -0.4236, -0.4236, -0.4236, -0.4236,  0.5953, -0.4236, -0.3374, -0.4236,\n",
            "        -0.4236, -0.4236,  0.6173, -0.4236,  3.2902, -0.4236, -0.4236, -0.4236,\n",
            "        -0.4236, -0.4236, -0.4236, -0.2337,  3.3076, -0.4236, -0.4236, -0.4236,\n",
            "        -0.4236, -0.4236, -0.4236, -0.4169, -0.4236,  0.1810, -0.4236, -0.4236,\n",
            "        -0.3793, -0.4236, -0.4236, -0.4236,  3.2962, -0.4236, -0.4236, -0.4236,\n",
            "        -0.4236,  0.6501,  0.5333,  5.5567, -0.4236, -0.4236, -0.1687,  2.7202,\n",
            "        -0.4236, -0.4236, -0.4236, -0.4236, -0.4236, -0.4236, -0.1406, -0.4236,\n",
            "        -0.4236, -0.4236, -0.4236, -0.4236,  0.7577,  2.2245,  0.3278, -0.4236,\n",
            "        -0.4236, -0.4236, -0.4236,  0.2500, -0.4236, -0.4236,  0.0781, -0.4236,\n",
            "        -0.4236,  0.5081, -0.4236,  0.0947, -0.4236, -0.4236, -0.4236, -0.4236,\n",
            "        -0.4236,  0.8271, -0.4236, -0.4236,  1.5109,  0.0850, -0.4236,  0.1519,\n",
            "        -0.4236,  0.7269, -0.4236,  1.9567], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 7/22  [========>.....................] - 12.5stensor([0.7500, 0.5000, 0.7500, 0.2500, 0.7500, 1.0000, 0.7500, 0.5000, 0.5000,\n",
            "        0.7500, 0.7500, 0.5000, 0.5000, 0.7500, 0.2500, 0.2500, 0.7500, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000, 0.2500, 0.2500,\n",
            "        0.7500, 0.7500, 0.7500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.7500, 0.5000, 0.0000, 0.2500, 0.5000, 0.2500, 0.5000, 0.0000, 0.2500,\n",
            "        0.5000, 0.0000, 0.7500, 0.5000, 0.7500, 0.5000, 0.5000, 0.5000, 0.7500,\n",
            "        0.0000, 0.7500, 0.2500, 0.2500, 0.7500, 0.5000, 0.5000, 0.7500, 0.5000,\n",
            "        0.0000, 0.7500, 0.2500, 0.5000, 0.5000, 0.2500, 0.5000, 0.7500, 0.5000,\n",
            "        0.5000, 0.7500, 0.5000, 0.5000, 0.2500, 0.2500, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.2500, 0.5000, 0.7500, 0.5000, 0.2500, 0.5000, 0.5000, 1.0000,\n",
            "        0.7500, 0.5000, 0.7500, 0.5000, 0.2500, 1.0000, 0.5000, 0.2500, 0.7500,\n",
            "        0.5000], device='cuda:0') tensor([-0.0387, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345,\n",
            "        -0.4345, -0.4345,  0.4982, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345,\n",
            "        -0.4345, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345,  0.1473, -0.4345,\n",
            "        -0.4345, -0.4345,  0.7755,  0.4338, -0.4345, -0.4011, -0.4345,  1.7910,\n",
            "        -0.4345, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345, -0.3704, -0.4345,\n",
            "        -0.4345, -0.4345,  3.9142,  0.1229, -0.4345, -0.4345, -0.4345,  0.6227,\n",
            "        -0.4345, -0.4345, -0.4345, -0.4345, -0.4345,  0.8529, -0.4345, -0.4345,\n",
            "         1.9960,  2.9528, -0.4345,  1.1529,  3.2624, -0.4345,  0.8540, -0.4345,\n",
            "        -0.4345, -0.4345,  0.1180,  0.3273, -0.3222, -0.4345, -0.4345, -0.4345,\n",
            "         0.2240, -0.4345, -0.0333,  2.6998, -0.4345, -0.4345, -0.4345, -0.4345,\n",
            "        -0.4345,  0.3210, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345, -0.4345,\n",
            "        -0.4345,  3.8668,  1.8522, -0.4345, -0.0628, -0.4345, -0.4345,  3.7245,\n",
            "        -0.4345, -0.4345, -0.4345, -0.4345], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 8/22  [=========>....................] - 14.5stensor([0.7500, 0.5000, 0.5000, 0.2500, 1.0000, 0.5000, 0.2500, 0.5000, 0.2500,\n",
            "        0.5000, 0.5000, 0.0000, 0.5000, 0.0000, 1.0000, 0.5000, 0.2500, 0.5000,\n",
            "        0.0000, 0.7500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7500, 0.2500,\n",
            "        0.2500, 0.2500, 0.7500, 0.7500, 0.5000, 0.7500, 0.7500, 0.2500, 0.2500,\n",
            "        0.2500, 0.5000, 0.7500, 0.5000, 0.2500, 0.2500, 0.7500, 0.2500, 0.7500,\n",
            "        0.7500, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.7500, 0.5000, 1.0000, 0.7500, 0.5000, 0.2500, 0.5000, 0.2500, 0.5000,\n",
            "        0.2500, 0.2500, 0.5000, 0.0000, 0.0000, 0.5000, 0.5000, 0.5000, 0.0000,\n",
            "        0.5000, 0.7500, 0.5000, 0.2500, 0.5000, 0.7500, 0.7500, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7500, 0.2500,\n",
            "        0.2500, 0.0000, 0.7500, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.7500], device='cuda:0') tensor([ 0.1518, -0.4872,  0.3099, -0.4872, -0.4872, -0.4872,  1.2718, -0.4872,\n",
            "        -0.4872, -0.4872, -0.4872, -0.4872, -0.4872, -0.4872, -0.4872,  0.0497,\n",
            "        -0.4872,  0.7112, -0.4872, -0.4872,  2.2289,  0.1117, -0.4872, -0.4872,\n",
            "        -0.4872, -0.4872, -0.4872, -0.4872, -0.4872,  2.8761, -0.4872, -0.4872,\n",
            "        -0.4788, -0.4872,  1.0195,  0.7467,  1.5054,  2.9603, -0.4872, -0.4872,\n",
            "        -0.4872,  0.1218, -0.4872, -0.4872, -0.4872, -0.4872, -0.4872, -0.4872,\n",
            "         0.4494,  0.8142, -0.4872, -0.4872,  2.0055, -0.4872, -0.4872, -0.4872,\n",
            "        -0.4872, -0.4872,  1.2358, -0.4872,  0.0756, -0.4872,  0.1213, -0.2062,\n",
            "         1.7419,  5.4867, -0.4872, -0.4872, -0.4872,  1.6382, -0.4872, -0.4872,\n",
            "        -0.4872, -0.4872,  0.2939,  0.8745,  0.3544, -0.4872, -0.4872, -0.4872,\n",
            "        -0.4872,  2.1814, -0.4872, -0.4872, -0.4872,  1.0445, -0.4872, -0.4872,\n",
            "        -0.4872, -0.4872, -0.4872, -0.4872,  2.4098, -0.4872, -0.4872, -0.4872,\n",
            "        -0.4872, -0.4872, -0.4872, -0.4872], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            " 9/22  [===========>..................] - 16.6stensor([0.5000, 0.5000, 0.2500, 0.0000, 0.7500, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 1.0000, 0.7500, 0.5000, 0.7500, 0.2500, 0.2500, 0.5000, 0.5000,\n",
            "        0.7500, 0.2500, 0.5000, 0.0000, 0.5000, 0.2500, 0.5000, 1.0000, 0.5000,\n",
            "        0.7500, 0.5000, 0.7500, 0.5000, 0.0000, 0.5000, 1.0000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.5000, 0.5000, 0.5000, 0.7500,\n",
            "        0.5000, 0.5000, 0.7500, 0.5000, 0.7500, 0.5000, 0.7500, 0.5000, 0.5000,\n",
            "        0.5000, 0.2500, 0.2500, 0.5000, 0.2500, 0.2500, 0.5000, 0.2500, 0.5000,\n",
            "        0.5000, 0.7500, 0.7500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.2500,\n",
            "        0.7500, 0.5000, 0.7500, 0.5000, 0.7500, 0.7500, 0.7500, 0.5000, 0.7500,\n",
            "        0.5000, 1.0000, 0.5000, 0.0000, 0.0000, 0.2500, 0.5000, 0.7500, 0.2500,\n",
            "        0.0000, 0.5000, 0.7500, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000,\n",
            "        0.5000], device='cuda:0') tensor([ 1.4559, -0.4250, -0.4250, -0.4250,  0.8005, -0.4250, -0.4250, -0.4250,\n",
            "        -0.4250, -0.4250, -0.4250,  0.5160, -0.0109, -0.4250, -0.4250, -0.4250,\n",
            "        -0.4250, -0.4250, -0.4250,  0.9410, -0.4250, -0.4250, -0.4250, -0.4250,\n",
            "        -0.4250,  3.9068, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250,\n",
            "        -0.4250,  1.8105, -0.4250, -0.4250, -0.4250, -0.4250,  2.9717, -0.4247,\n",
            "        -0.4250, -0.4250, -0.4250, -0.4250, -0.4250,  2.8514, -0.4250, -0.4250,\n",
            "         0.7452, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250,  2.3463, -0.4250,\n",
            "        -0.4250, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250,\n",
            "        -0.4250, -0.4250, -0.4250, -0.4250, -0.4250,  0.4412, -0.4250,  0.3700,\n",
            "         0.1440,  3.1634, -0.4250,  0.5951,  3.0564,  2.8441, -0.4250, -0.4250,\n",
            "        -0.4250, -0.4250, -0.4250, -0.4250, -0.4250,  1.7267, -0.4250, -0.4250,\n",
            "        -0.4250, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250, -0.4250,\n",
            "        -0.1078, -0.4250, -0.4250,  3.0058], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n",
            "10/22  [============>.................] - 18.6stensor([0.2500, 0.2500, 1.0000, 0.5000, 0.5000, 0.5000, 0.2500, 0.5000, 0.2500,\n",
            "        0.7500, 0.7500, 0.2500, 0.5000, 0.5000, 0.7500, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.5000, 0.7500, 0.0000, 0.2500, 0.5000, 0.2500, 0.7500,\n",
            "        0.2500, 1.0000, 1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 1.0000, 0.2500, 0.5000, 0.7500, 0.5000, 0.2500, 0.5000,\n",
            "        0.5000, 1.0000, 0.5000, 0.7500, 0.5000, 0.7500, 0.5000, 0.5000, 0.5000,\n",
            "        0.5000, 0.5000, 0.7500, 1.0000, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000,\n",
            "        0.5000, 0.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7500, 0.5000,\n",
            "        0.5000, 0.0000, 0.2500, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.7500,\n",
            "        0.2500, 0.5000, 0.7500, 0.5000, 0.2500, 0.2500, 0.5000, 0.7500, 0.5000,\n",
            "        0.2500, 0.0000, 0.5000, 0.5000, 0.2500, 0.5000, 0.5000, 0.5000, 0.7500,\n",
            "        0.7500], device='cuda:0') tensor([ 2.7013, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653, -0.2604,  0.1899,\n",
            "        -0.3653, -0.3653, -0.3653,  1.8455, -0.3653, -0.3653, -0.3653,  1.2527,\n",
            "        -0.3653, -0.3653, -0.3653,  0.2172, -0.3653, -0.3653,  0.3932, -0.3653,\n",
            "        -0.3653, -0.3653,  0.9144, -0.3653,  0.5580, -0.3653, -0.3653,  0.0616,\n",
            "        -0.3653, -0.3653,  0.2179, -0.3653, -0.3653, -0.3653,  0.1788, -0.3653,\n",
            "        -0.3653,  3.6250, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653,\n",
            "        -0.3653, -0.3653,  5.8540, -0.3653,  0.6138, -0.3653, -0.3653, -0.3653,\n",
            "        -0.3653, -0.3653, -0.3653, -0.3653, -0.3653,  1.4581, -0.3653,  0.3961,\n",
            "        -0.3653, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653, -0.1199, -0.3653,\n",
            "        -0.3653, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653,  1.5516, -0.2960,\n",
            "        -0.3653, -0.3653,  0.1278, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653,\n",
            "         1.2330, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653, -0.3653, -0.3181,\n",
            "         0.3354, -0.3653,  4.6691, -0.3653], device='cuda:0',\n",
            "       grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-d0d237488f3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNCDG_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOkg4Ctc9Lf3"
      },
      "source": [
        "def permutation_estimator(scores,thau):\n",
        "  n = scores.shape[0]\n",
        "  scores = scores.reshape((n,1))\n",
        "  As = torch.empty((n,n))\n",
        "  As = As\n",
        "  for i in range(As.shape[0]):\n",
        "    for j in range(As.shape[1]):\n",
        "      As[i,j] = abs(scores[i] - scores[j])\n",
        "  ones = torch.ones((n,1))\n",
        "  ones = ones\n",
        "  permute = torch.zeros((n,n))\n",
        "  permute = permute\n",
        "  for i in range(1,n+1):\n",
        "    a = torch.argmax(softmax(((n+1-(2*i))*scores - torch.matmul(As,ones) )/ thau).reshape(n))\n",
        "    \n",
        "    permute[i-1,a ] = 1.0\n",
        "  return permute\n",
        "\n",
        "def softmax(a):\n",
        "  return torch.exp(a) / torch.sum(torch.exp(a))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OYoJjRQsvSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ffef02-31ca-4715-f547-2064aa45b092"
      },
      "source": [
        "\n"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9fNXwgI9Vtq",
        "outputId": "5f82e4e8-d552-4d27-f137-2b89eb3499df"
      },
      "source": [
        "a= torch.tensor([7.0,1.0,4.0,3.0,5.6])\n",
        "b = torch.tensor([2.0,7.0,0.0,1.0,12.0])\n",
        "b_rank = torch.tensor([- ,2 , - , 2 , 1])\n",
        "n = b.shape[0]\n",
        "p_hat = permutation_estimator(a,1)\n",
        "1 -(6*torch.sum(torch.abs(torch.matmul(b,p_hat) - torch.arange(1,5,dtype=torch.float32))**2))/(n*(n**2-1))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smud7iTWEICj"
      },
      "source": [
        "\n",
        "scipy.stats.spearmanr(a.detach().cpu().numpy(), b.detach().cpu().numpy())[0]\n"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQImY-EJB8p3",
        "outputId": "50822c7d-f4cb-4573-8f94-77a778ed0674"
      },
      "source": [
        ""
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6000000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SstPP0mAELU"
      },
      "source": [
        "rank = torch.arange(1,6,dtype=torch.float32)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyQ6iMw6A9Ys"
      },
      "source": [
        "p_hat_inv = torch.inverse(p_hat)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeaWXQPC97oU",
        "outputId": "fd6cbe22-51c9-4d6e-9041-4ba16471117f"
      },
      "source": [
        "torch.matmul(torch.inverse(p_hat) , rank)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 5., 2., 3., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFRFowo4_8d3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}